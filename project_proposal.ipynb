{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Proposal**\n",
    "## Title: ...\n",
    "Group 8\n",
    "\n",
    "Team members: ...\n",
    "\n",
    "## **Introduction**\n",
    "Heart disease is a subset of cardiovascular diseases, the global leading cause of death. From the Framingham Heart Study, many different factors, such as age, are found to be correlated with heart disease. \n",
    "\n",
    "The question we will try to answer with this project is: Can we use `age`, `exang` (exercise induced angina), `??` to predict whether someone will be diagnosed with heart disease (yes or no)? \n",
    "\n",
    "The dataset we will use is \"Heart Disease\" Data Set, consisting of 14 attributes: \n",
    "* `age` (in years)\n",
    "* `sex` (1 = male; 0 = female)\n",
    "* `cp`: Chest pain type\n",
    "    - Value 1: typical angina\n",
    "    - Value 2: atypical angina\n",
    "    - Value 3: non-anginal pain\n",
    "    - Value 4: asymptomatic\n",
    "* `trestbps`: resting blood pressure (mmHg)\n",
    "* `chol`: serum cholesterol (mg/dl)\n",
    "* `fbs`: fasting blood sugar > 120 mg/dl (1 = true; 0 = false) \n",
    "* `restecg`: resulting electrocardiographic results\n",
    "* `thalach`: maximum heart rate achieved \n",
    "* `exang`: exercise induced angina (1= yes; 0= no)\n",
    "* `oldpeak`: ST depression induced by exercise relative to rest\n",
    "*  `slope`: slope of peak exercise ST segment\n",
    "    - Value 1: upsloping = 3\n",
    "    - Value 2: flat = 2\n",
    "    - Value 3: downsloping = 1\n",
    "* `ca`: number of major vessels (0, 1, 2, 3)\n",
    "* `thal`: \n",
    "    - Value 3 = normal\n",
    "    - Value 6 = fixed defect\n",
    "    - Value 7 = reversible defect\n",
    "* `num`: diagnosis of heart disease\n",
    "    - Value 0: Healthy, <50% diameter narrowing\n",
    "    - Value 1: Diagnosed with stage 1, >50% diameter narrowing\n",
    "    - Value 2: Diagnosed with stage 2, >50% diameter narrowing\n",
    "    - Value 3: Diagnosed with stage 3, >50% diameter narrowing\n",
    "    - Value 4: Diagnosed with stage 4, >50% diameter narrowing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preliminary exploratory data analysis**\n",
    "\n",
    "### Reading and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell before continuing. \n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this following cell we perform 3 steps:\n",
    "\n",
    "* We read the data directly from the internet into this R notebook.\n",
    "* Since the data doesn't have the columns' names in its file, we explicitly write the names from the information we find in https://archive.ics.uci.edu/ml/datasets/Heart+Disease.\n",
    "* We remove rows which have null values by filtering. In this case null values are represented as \"?\", and we know that `ca` and `thal` have some of this null values\n",
    "* We change the data type of some of the variables since in the webpage mentioned above we can see that some variables should be categorical,as they only have a few possible values.\n",
    "* We create a new variable from `num`. Instead of having different values of diagnosed (`num`= 1, 2, 3 or 4) we just consider if the person has been diagnosed with a heart disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "data <- read_csv(url, col_names = c(\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\",\n",
    "                                    \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\")) %>%\n",
    "        filter(ca != \"?\" & thal != \"?\") %>%\n",
    "        mutate(sex = as.factor(sex), cp = as.factor(cp), fbs = as.factor(fbs), restecg = as.factor(restecg),\n",
    "               exang = as.factor(exang), slope = as.factor(slope), thal = as.factor(thal), num = as.factor(num),\n",
    "               ca = as.factor(ca),\n",
    "               target = ifelse(num==0, 0, 1))\n",
    "        \n",
    "\n",
    "head(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can see that the data looks tidy. The dataset already contained tidy data, therefore we only needed to add the columns' names, remove the null values and the specify data types, plus we aadditionally created a new variable to simplify answering our question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test\n",
    "\n",
    "For the next part, we want to explore our dataset, but only the training dataset. Therefore we first will split the data into 2 sub-datasets. We will use 75% of our data for training and the variable we want to classify is `num`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split <- initial_split(data, prop = 0.75, strata = num)  \n",
    "data_train <- training(data_split)   \n",
    "data_test <- testing(data_split)\n",
    "\n",
    "head(data_train, 5)\n",
    "head(data_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the size we originally had from the whole dataset, as well as the size of the training dataset and the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(data)\n",
    "nrow(data_train)\n",
    "nrow(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Summary Table\n",
    "We perform an exploratory data analysis of the data and show it in a table format.  \n",
    "\n",
    "CAN USE THIS:\n",
    "summarize the data in at least one table (this is ). An example of a useful table could be one that reports the number of observations in each class, the means of the predictor variables you plan to use in your analysis and how many rows have missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(mlr)\n",
    "#summarizeColumns(data_train)\n",
    "\n",
    "# CAN'T USE BECAUSE CAN'T DOWNLOAD mlr PACKAGE :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_data <- data_train %>%\n",
    "    group_by(num) %>%\n",
    "    summarize(n = n(),\n",
    "              mean_age = mean(age, na.rm = TRUE),\n",
    "              mean_trestbps = mean(trestbps, na.rm = TRUE),\n",
    "              mean_chol = mean(chol, na.rm = TRUE),\n",
    "              mean_thalach = mean(thalach, na.rm = TRUE),\n",
    "              mean_oldpeak = mean(oldpeak, na.rm = TRUE),\n",
    "              majority_sex = sex[n == max(n)][1],\n",
    "              majority_cp = cp[n == max(n)][1],\n",
    "              majority_fbs = fbs[n == max(n)][1],\n",
    "              majority_restecg = restecg[n == max(n)][1],\n",
    "              majority_exang = exang[n == max(n)][1],\n",
    "              majority_slope = slope[n == max(n)][1],\n",
    "              majority_ca = ca[n == max(n)][1],\n",
    "              majority_thal = thal[n == max(n)][1])\n",
    "\n",
    "EDA_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Visualization Analysis\n",
    "\n",
    "Now we perform another exploratory data analysis to visualize the data with some relevant plots to our analysis. \n",
    "\n",
    "WE CAN USE: An example of a useful visualization could be one that compares the distributions of each of the predictor variables you plan to use in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thalach, age\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 8) #Remember to set your plot sizes to an appropiate size\n",
    "\n",
    "# add the code for your plot here!\n",
    "smoke_plot <- data_train %>%\n",
    "    ggplot(aes(x = thalach, y = oldpeak)) + \n",
    "        geom_point(aes(colour=num), alpha = 0.6, size=4) + # Deals with the transparency of the points, set it to an appropiate value\n",
    "        labs(x= \"x\", y= \"y\", colour=\"Predicted group\") + \n",
    "        ggtitle(\"plot 1\") +\n",
    "        scale_color_manual(values=c(\"#000000\", \"#F5213D\", \"#56B4E9\", \"#39C45E\", \"#E6FF00\"))\n",
    "\n",
    "\n",
    "smoke_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num <- data %>%\n",
    "    select(age, trestbps, chol, thalach, oldpeak)\n",
    "\n",
    "res <- cor(data_num)\n",
    "round(res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggcorrplot)\n",
    "options(repr.plot.width = 12, repr.plot.height = 12) #Remember to set your plot sizes to an appropiate size\n",
    "\n",
    "model.matrix(~0+., data=data) %>% \n",
    "  cor(use=\"pairwise.complete.obs\") %>% \n",
    "  ggcorrplot(show.diag = F, type=\"lower\", lab=TRUE, lab_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
